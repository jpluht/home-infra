---
- name: Configure GPU Nodes for LLM Models and iSCSI Hard Drives
  hosts: gpu_node
  become: yes
  gather_facts: yes
  collections:
    - ansible.posix
    - community.general

  vars:
    iscsi_target_ip: "{{ gpu_node_vars.iscsi_target_ip | default('10.0.1.20') }}"
    iscsi_target_iqn: "{{ gpu_node_vars.iscsi_target_iqn | default('iqn.2024-01.local.cluster:target') }}"
    llm_models_dir: "/opt/llm_models"
    python_version: "3.10"

  tasks:
    - name: Update package cache
      apt:
        update_cache: yes
      when: ansible_os_family in ['Debian', 'Ubuntu']

    - name: Install essential packages
      apt:
        name:
          - python{{ python_version }}
          - python{{ python_version }}-pip
          - python{{ python_version }}-venv
          - git
          - curl
          - wget
          - open-iscsi
          - multipath-tools
        state: present
      when: ansible_os_family in ['Debian', 'Ubuntu']

    - name: Install NVIDIA drivers and CUDA (if GPU present)
      apt:
        name:
          - nvidia-driver-470
          - nvidia-cuda-toolkit
        state: present
      ignore_errors: yes
      when: ansible_os_family in ['Debian', 'Ubuntu']

    - name: Install Python packages for LLM
      pip:
        name:
          - torch
          - torchvision
          - torchaudio
          - transformers
          - accelerate
          - datasets
          - huggingface_hub
        executable: pip3

    - name: Create directory for LLM models
      file:
        path: "{{ llm_models_dir }}"
        state: directory
        mode: '0755'

    - name: Configure iSCSI initiator
      lineinfile:
        path: /etc/iscsi/iscsid.conf
        regexp: '^node.session.auth.authmethod = '
        line: 'node.session.auth.authmethod = CHAP'
      notify: restart iscsi

    - name: Discover iSCSI targets
      command: iscsiadm -m discovery -t sendtargets -p {{ iscsi_target_ip }}
      register: discovery_output
      ignore_errors: yes

    - name: Login to iSCSI target
      command: iscsiadm -m node -T {{ iscsi_target_iqn }} -p {{ iscsi_target_ip }} --login
      when: discovery_output.rc == 0
      ignore_errors: yes

    - name: Ensure multipath is configured
      service:
        name: multipathd
        state: started
        enabled: yes

    - name: Create LLM models directory structure
      file:
        path: "{{ llm_models_dir }}/{{ item }}"
        state: directory
        mode: '0755'
      loop:
        - cache
        - models
        - scripts

    - name: Set up basic LLM inference script
      copy:
        dest: "{{ llm_models_dir }}/scripts/inference.py"
        content: |
          #!/usr/bin/env python3
          from transformers import pipeline
          import torch

          def main():
              device = 0 if torch.cuda.is_available() else -1
              classifier = pipeline("sentiment-analysis", device=device)
              result = classifier("Test input")
              print(result)

          if __name__ == "__main__":
              main()
        mode: '0755'

  handlers:
    - name: restart iscsi
      service:
        name: iscsid
        state: restarted
